# Experiment 1 ‚Äì Prompt Engineering  
**Author:** Kantha Sishanth S 

**Reg No:** 212222100020

---

## üìå Prompt  
Prepare a comprehensive comparative report on how different Generative AI platforms, specifically **ChatGPT** and **Perplexity AI**, function. The report should explain their underlying **Large Language Model (LLM)** architectures, data sources, response generation methods, accuracy, and relevance in answering queries.  
The comparison should include:  
- User interaction styles  
- Fact-checking abilities  
- Integration features  

---

## üéØ Aim  
To develop a comprehensive report on the fundamentals of **Generative AI** and **Large Language Models (LLMs)**, with a focus on ChatGPT and Perplexity AI ‚Äî how they work, their architectures, data handling, and answer relevance.

---

## üìù Abstract  
This report explores the fundamentals of Generative AI and LLMs through a practical comparison of ChatGPT and Perplexity AI.  
While both use transformer-based architectures, their **data sourcing**, **retrieval methods**, and **answer styles** differ significantly.  
- **ChatGPT** excels in conversational depth and creativity.  
- **Perplexity AI** focuses on factual accuracy and real-time information retrieval with citations.  

The **impact of scaling** LLMs on both tools is also discussed.

---

## üìö Table of Contents
1. Introduction to Generative AI  
2. ChatGPT: Overview & Working  
3. Perplexity AI: Overview & Working  
4. Architecture Comparison  
5. Applications & Strengths  
6. Impact of Scaling in LLMs  
7. Limitations & Ethical Considerations  
8. Conclusion  
9. References  

---

## 1Ô∏è‚É£ Introduction to Generative AI  
Generative AI refers to systems that can produce new content ‚Äî text, images, audio ‚Äî by learning from massive datasets.  
LLMs like GPT-4 use **deep learning** and **transformer architectures** to understand context, generate coherent responses, and adapt to different tasks.

---

## 2Ô∏è‚É£ ChatGPT: Overview & Working
- **Developer:** OpenAI  
- **Architecture:** GPT-3.5, GPT-4 (Transformer-based)  
- **Knowledge Source:** Pre-trained datasets + optional browsing for live data  
- **Mechanism:**  
  1. User inputs a prompt.  
  2. Model tokenizes input, processes via attention layers.  
  3. Generates next tokens until completion.  
- **Strengths:** Highly conversational, great for creative writing, coding, and explanations.  
- **Limitations:** Without browsing, info can be outdated; no default citations.

---

## 3Ô∏è‚É£ Perplexity AI: Overview & Working
- **Developer:** Perplexity.ai  
- **Architecture:** GPT-3.5/GPT-4 + Search Retrieval  
- **Knowledge Source:** Real-time web search + LLM knowledge  
- **Mechanism:**  
  1. User inputs query.  
  2. Retrieves top web results.  
  3. Summarizes and cites sources in real time.  
- **Strengths:** Always up-to-date, provides clickable citations.  
- **Limitations:** Less creative; quality depends on search results.

---

## 4Ô∏è‚É£ Architecture Comparison

| Feature        | ChatGPT                                | Perplexity AI                              |
|----------------|----------------------------------------|--------------------------------------------|
| **Core Model** | GPT-3.5 / GPT-4 (Transformer)          | GPT-3.5 / GPT-4 + Search Retrieval         |
| **Data Source**| Pre-trained dataset, optional browsing | Live web data + LLM                        |
| **Citation**   | No (unless browsing enabled)           | Yes, always                                |
| **Update Freq**| Retraining or browsing                 | Real-time                                  |
| **Best At**    | Creative writing, coding, explanations | Fact-checking, research, current events    |

---

## 5Ô∏è‚É£ Applications & Strengths

**ChatGPT:**  
- Education & tutoring  
- Creative writing  
- Coding assistance  
- Concept explanations  

**Perplexity AI:**  
- Research assistance  
- News updates  
- Fact verification  
- Academic referencing  

---

## 6Ô∏è‚É£ Impact of Scaling in LLMs
Both tools benefit from **scaling laws** ‚Äî increasing model size, dataset size, and compute improves performance.  
- **ChatGPT:** Scaling from GPT-2 ‚Üí GPT-3 ‚Üí GPT-4 improved reasoning, context handling, and multilingual ability.  
- **Perplexity AI:** Gains from LLM scaling but also relies heavily on search algorithm efficiency.

---

## 7Ô∏è‚É£ Limitations & Ethical Considerations
- **ChatGPT:** Risk of outdated info without browsing; hallucinations.  
- **Perplexity AI:** May surface unreliable sources; weaker for creative tasks.  
- **Both:** Share risks of bias, misinformation, and privacy issues.

---

## 8Ô∏è‚É£ Conclusion
- **For creativity & deep conceptual explanation ‚Üí ChatGPT**  
- **For factual accuracy & up-to-date answers ‚Üí Perplexity AI**  
The choice depends on whether **depth** or **timeliness** matters more.

---

## üìñ References
1. OpenAI (2023). *GPT-4 Technical Overview*.  
2. Vaswani, A. et al. (2017). *Attention Is All You Need*.  
3. Perplexity.ai Official Documentation.  
4. Goodfellow, I. et al. (2014). *Generative Adversarial Nets*.  

---
